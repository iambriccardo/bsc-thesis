apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: syncdc-dpso
  namespace: spark-jobs
spec:
  type: Scala
  mode: cluster
  image: "riccardobusetti/spark:latest"
  imagePullPolicy: IfNotPresent
  mainClass: MainKt
  mainApplicationFile: "local:///opt/spark/jars/dpso.jar"
  arguments:
    - "--sync"
    - "--distributed-pos-eval"
    - "--fitness-eval-delay=50"
    - "--iterations=10"
    - "--particles=20"
    - "--fog-nodes=300"
    - "--modules=300"
    - "--result-path=/spark-volume/syncdc-best-position.txt"
    - "--keep-alive"
  sparkVersion: "3.1.1"
  restartPolicy:
    type: Never
  volumes:
    - name: spark-data
      persistentVolumeClaim:
        claimName: local-pvc
  driver:
    cores: 1
    #coreLimit: "1200m"
    #memory: "512m"
    securityContext:
      allowPrivilegeEscalation: false
      runAsUser: 0
    volumeMounts:
      - name: "spark-data"
        mountPath: "/spark-volume"
    labels:
      version: 3.1.1
    serviceAccount: spark
  executor:
    cores: 2
    instances: 3
    #memory: "512m"
    labels:
      version: 3.1.1
